{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from utils import create_matrix_from_raw, RAND_SEED\n",
    "from models import SVD, IRSVD, Baseline, GBias, SVP, SVT, RSVD\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some usefull functions for anaylisis and plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams.update({'font.size': 15})\n",
    "def plot_graph(xlabel, ylabel, x_vals, y_vals, name):\n",
    "    fig, axs = plt.subplots(1, 1, figsize=(9, 5), sharey=True)\n",
    "    axs.plot(x_vals, y_vals)\n",
    "    min_yval = min(y_vals)\n",
    "    min_idx = y_vals.index(min_yval)\n",
    "    min_xval = x_vals[min_idx]\n",
    "    axs.plot(min_xval, min_yval, \"ro\")\n",
    "    axs.set_xlabel(xlabel)\n",
    "    axs.set_ylabel(ylabel)\n",
    "    axs.set_xticks(x_vals)\n",
    "    fig.savefig(\"./experiments_out/\"+name+\".pdf\", bbox_inches='tight')\n",
    "    # fig.suptitle('Categorical Plotting')\n",
    "\n",
    "def plot_graph2(train_err, test_err, name):\n",
    "    fig, axs = plt.subplots(1, 1, figsize=(9, 5), sharey=True)\n",
    "    x_vals = list(range(1,len(train_err)+1))\n",
    "    axs.plot(x_vals, train_err, label=\"train\")\n",
    "    axs.plot(x_vals, test_err, label=\"test\")\n",
    "    axs.legend(loc=\"lower left\")\n",
    "    min_yval = min(test_err)\n",
    "    min_idx = test_err.index(min_yval)\n",
    "    min_xval = x_vals[min_idx]\n",
    "    axs.plot(min_xval, min_yval, \"ro\")\n",
    "    axs.set_xlabel(\"Epoch\")\n",
    "    axs.set_ylabel(\"RMSE\")\n",
    "    axs.set_xticks(x_vals)\n",
    "    fig.savefig(\"./experiments_out/\"+name+\".pdf\", bbox_inches='tight')\n",
    "\n",
    "def analyse_results(results):\n",
    "    best_epoch = None\n",
    "    mean = None\n",
    "    std = None\n",
    "    \n",
    "    min_errors = []\n",
    "    for idx, result in enumerate(results):\n",
    "        test_rmse_lst = result[\"test_rmse\"]\n",
    "        if idx == 0:\n",
    "            min_error = min(test_rmse_lst)\n",
    "            best_epoch = test_rmse_lst.index(min_error)\n",
    "        else:\n",
    "            min_error = test_rmse_lst[best_epoch]\n",
    "        min_errors.append(min_error)\n",
    "    \n",
    "    min_errors = np.array(min_errors)\n",
    "    mean = min_errors.mean()\n",
    "    std = min_errors.std()\n",
    "    return mean, std, best_epoch+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KFolds\n",
    "- Hyperparameters tunning levereging k=10 folds cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pd = pd.read_csv(\"./data/data_train.csv\")\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=RAND_SEED)\n",
    "# Check whether we have the same splits\n",
    "for train_set, test_set in kf.split(data_pd):\n",
    "    print(train_set)\n",
    "    print(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD - Baseline 1\n",
    "- In this experiment we will find the best value for k (the most important singular values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SVD finding best k value\")\n",
    "data = dict()\n",
    "for k in range(1,21):\n",
    "    results = []\n",
    "    for idx, (train_set, test_set) in enumerate(kf.split(data_pd)):\n",
    "        train_data = data_pd.iloc[train_set]\n",
    "        test_data = data_pd.iloc[test_set]\n",
    "        \n",
    "        train_matrix = create_matrix_from_raw(train_data)\n",
    "        test_matrix = create_matrix_from_raw(test_data)\n",
    "        \n",
    "        model = SVD(train_matrix, K=k)\n",
    "        result = model.train(test_matrix=test_matrix)\n",
    "        results.append(result)\n",
    "    mean, std, _ = analyse_results(results)\n",
    "    print(f\"For k={k}: Mean={mean}, Std={std}\")\n",
    "    data[k] = mean\n",
    "ks = list(data.keys())\n",
    "scores = list(data.values())\n",
    "plot_graph(\"Number of singular values\", \"Avg. RMSE\", ks, scores, \"svd\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALS (U,V decomposition) - Baseline 2\n",
    "- In this experiment we will use the best value for k=3 and we will explore the number of epochs necessary until convergence.\n",
    "- We will fix $λ$ to 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will only perform this test on the first fold\n",
    "print(\"Finding number of epochs until convergence\")\n",
    "data = dict()\n",
    "results = []\n",
    "for idx, (train_set, test_set) in enumerate(kf.split(data_pd)):\n",
    "    train_data = data_pd.iloc[train_set]\n",
    "    test_data = data_pd.iloc[test_set]\n",
    "    \n",
    "    train_matrix = create_matrix_from_raw(train_data)\n",
    "    test_matrix = create_matrix_from_raw(test_data)\n",
    "    \n",
    "    model = Baseline(train_matrix, K=3, lambda1=0.1, epochs=5)\n",
    "    result = model.train(test_matrix=test_matrix)\n",
    "    results.append(result)\n",
    "    break\n",
    "\n",
    "print(f\"For k=3 and lambda=0.1\")\n",
    "epochs = list(range(1,6))\n",
    "scores = results[0][\"test_rmse\"]\n",
    "plot_graph(\"Epoch\", \"RMSE\", epochs, scores, \"als\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cross validation score for k=3, λ=0.1, epochs=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for idx, (train_set, test_set) in enumerate(kf.split(data_pd)):\n",
    "    train_data = data_pd.iloc[train_set]\n",
    "    test_data = data_pd.iloc[test_set]\n",
    "    \n",
    "    train_matrix = create_matrix_from_raw(train_data)\n",
    "    test_matrix = create_matrix_from_raw(test_data)\n",
    "    \n",
    "    model = Baseline(train_matrix, K=3, lambda1=0.1, epochs=5)\n",
    "    result = model.train(test_matrix=test_matrix)\n",
    "    results.append(result)\n",
    "mean, std, _ = analyse_results(results)\n",
    "print(f\"For k=3: Mean={mean}, Std={std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global biases (ALS2)\n",
    "- In this experiment we will find the best value of $λ$ (regularization factor)\n",
    "- We will also automatically find the epoch at which this method converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Global biases finding best lambda value\")\n",
    "data = dict()\n",
    "for lambda1 in [0.0005, 0.001, 0.0015, 0.002, 0.0025, 0.003, 0.01]:\n",
    "    results = []\n",
    "    for idx, (train_set, test_set) in enumerate(kf.split(data_pd)):\n",
    "        train_data = data_pd.iloc[train_set]\n",
    "        test_data = data_pd.iloc[test_set]\n",
    "        \n",
    "        train_matrix = create_matrix_from_raw(train_data)\n",
    "        test_matrix = create_matrix_from_raw(test_data)\n",
    "        \n",
    "        model = GBias(train_matrix, lambda1=lambda1, epochs=5)\n",
    "        result = model.train(test_matrix=test_matrix)\n",
    "        results.append(result)\n",
    "    mean, std, best_epoch = analyse_results(results)\n",
    "    print(f\"For lambda={lambda1}: Mean={mean}, Std={std}, Epoch(conv.)={best_epoch}\")\n",
    "    data[lambda1] = mean\n",
    "lambdas = list(data.keys())\n",
    "scores = list(data.values())\n",
    "plot_graph(\"Regularization\", \"Avg. RMSE\", lambdas, scores, \"global\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Singular value thresholding (SVT) / Nuclear norm relaxation\n",
    "- In this experiment we will find the best value for $τ$.\n",
    "- We will also learn for free the number of epochs necessary to converge.\n",
    "- Learning rate will be set to 1.2 (reference paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SVT finding best tau value\")\n",
    "data = dict()\n",
    "for tau in range(200,1600,200):\n",
    "    results = []\n",
    "    for idx, (train_set, test_set) in enumerate(kf.split(data_pd)):\n",
    "        train_data = data_pd.iloc[train_set]\n",
    "        test_data = data_pd.iloc[test_set]\n",
    "        \n",
    "        train_matrix = create_matrix_from_raw(train_data)\n",
    "        test_matrix = create_matrix_from_raw(test_data)\n",
    "        \n",
    "        model = SVT(train_matrix, eta=1.2, tau=tau, epochs=23)\n",
    "        result = model.train(test_matrix=test_matrix)\n",
    "        results.append(result)\n",
    "    mean, std, best_epoch = analyse_results(results)\n",
    "    print(f\"For tau={tau}: Mean={mean}, Std={std}, Epoch(conv.)={best_epoch}\")\n",
    "    data[tau] = mean\n",
    "taus = list(data.keys())\n",
    "scores = list(data.values())\n",
    "plot_graph(\"Threshold\", \"Avg. RMSE\", taus, scores, \"svt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Singular value projection (SVP)\n",
    "- In this experiment we will find the best value for K\n",
    "- We will also learn for free the number of epochs necessary to converge.\n",
    "- Learning rate will be set to 5 (reference paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SVP finding best projection rank (k) value\")\n",
    "data = dict()\n",
    "for k in range(1,21):\n",
    "    results = []\n",
    "    for idx, (train_set, test_set) in enumerate(kf.split(data_pd)):\n",
    "        train_data = data_pd.iloc[train_set]\n",
    "        test_data = data_pd.iloc[test_set]\n",
    "        \n",
    "        train_matrix = create_matrix_from_raw(train_data)\n",
    "        test_matrix = create_matrix_from_raw(test_data)\n",
    "        \n",
    "        model = SVP(train_matrix,K=k, epochs=20)\n",
    "        result = model.train(test_matrix=test_matrix)\n",
    "        results.append(result)\n",
    "    mean, std, best_epoch = analyse_results(results)\n",
    "    print(f\"For k={k}: Mean={mean}, Std={std}, Epoch(conv.)={best_epoch}\")\n",
    "    data[k] = mean\n",
    "ks = list(data.keys())\n",
    "scores = list(data.values())\n",
    "plot_graph(\"Projection rank\", \"Avg. RMSE\", ks, scores, \"svp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improved Regularized SVD\n",
    "- In this experiment we will learn the best number of features (k)\n",
    "- We will set learning rate to 0.01, $λ_1$ to 0.02 and $λ_2$ to 0.05 (reference paper)\n",
    "- We will learn epochs to converge for free"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"IRSVD finding best number of features (k)\")\n",
    "data = dict()\n",
    "all_results = dict()\n",
    "for k in [75, 125, 175, 225, 275, 325, 375, 425]:\n",
    "    results = []\n",
    "    for idx, (train_set, test_set) in enumerate(kf.split(data_pd)):\n",
    "        train_data = data_pd.iloc[train_set]\n",
    "        test_data = data_pd.iloc[test_set]\n",
    "        \n",
    "        train_matrix = create_matrix_from_raw(train_data)\n",
    "        test_matrix = create_matrix_from_raw(test_data)\n",
    "        \n",
    "        model = IRSVD(train_matrix, biases=\"mean\", features=k, eta=0.01, lambda1=0.02, lambda2=0.05, epochs=18)\n",
    "        result = model.train(test_matrix=test_matrix)\n",
    "        results.append(result)\n",
    "    mean, std, best_epoch = analyse_results(results)\n",
    "    print(f\"For features={k}: Mean={mean}, Std={std}, Epoch(conv.)={best_epoch}\")\n",
    "    print(results)\n",
    "    data[k] = mean\n",
    "    all_results[k] = results\n",
    "ks = list(data.keys())\n",
    "scores = list(data.values())\n",
    "plot_graph(\"Number of features\", \"Avg. RMSE\", ks, scores, \"irsvd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this experiment we will present the event of overfitting for the best value of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_val = min(scores)\n",
    "min_idx = scores.index(min_val)\n",
    "k = ks[min_idx]\n",
    "results = all_results[k][0]\n",
    "plot_graph2(results[\"train_rmse\"], results[\"test_rmse\"], \"irsvd-overfitting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularized SVD\n",
    "- In this experiment we will learn the best number of features (k)\n",
    "- We will set learning rate to 0.01, $λ$ to 0.02 (reference paper)\n",
    "- We will learn epochs to converge for free"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RSVD finding best number of features (k)\")\n",
    "data = dict()\n",
    "for k in [75, 125, 175, 225, 275, 325, 375, 425]:\n",
    "    results = []\n",
    "    for idx, (train_set, test_set) in enumerate(kf.split(data_pd)):\n",
    "        train_data = data_pd.iloc[train_set]\n",
    "        test_data = data_pd.iloc[test_set]\n",
    "        \n",
    "        train_matrix = create_matrix_from_raw(train_data)\n",
    "        test_matrix = create_matrix_from_raw(test_data)\n",
    "        \n",
    "        model = RSVD(train_matrix, features=k, eta=0.01, lambda1=0.02, epochs=18)\n",
    "        result = model.train(test_matrix=test_matrix)\n",
    "        results.append(result)\n",
    "    mean, std, best_epoch = analyse_results(results)\n",
    "    print(f\"For features={k}: Mean={mean}, Std={std}, Epoch(conv.)={best_epoch}\")\n",
    "    data[k] = mean\n",
    "ks = list(data.keys())\n",
    "scores = list(data.values())\n",
    "plot_graph(\"Number of features\", \"Avg. RMSE\", ks, scores, \"rsvd\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0a87d56eeac580fc40402592e75d25bb128c24f68de3c5b4d3abca5cf6a5446a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
