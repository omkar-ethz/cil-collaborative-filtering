{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sr5kvYqx-4kA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "from utils import import_data_to_matrix_split, import_data_to_matrix, extract_submission\n",
        "from utils import get_rmse_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Global Bias Method\n",
        "- Idea: Each user and each item has a specific bias towards ratings\n",
        "\n",
        "## Data Preprocessings\n",
        "- Extract data to row-column format\n",
        "- Impute missing data with 0\n",
        "- Rating matrix A\n",
        "- Observation matrix Ω\n",
        "  \n",
        "## Global Bias\n",
        "- Global rating mean:\n",
        "$$μ = \\frac{\\sum_{u=1}^n \\sum_{i=1}^m ω_{ui}a_{ui}}{\\sum_{u=1}^n \\sum_{i=1}^m ω_{ui}}$$\n",
        "- User $u$ rating mean:\n",
        "$$μ_{(u,.)} = \\frac{\\sum_{i=1}^m ω_{ui}a_{ui}}{\\sum_{i=1}^m ω_{ui}}$$\n",
        "- Item $i$ rating mean:\n",
        "$$μ_{(.,i)} = \\frac{\\sum_{u=1}^n ω_{ui}a_{ui}}{\\sum_{u=1}^n ω_{ui}}$$\n",
        "- User $u$ rating bias: (Initial values for ALS)\n",
        "$$b_{(u,.)} = μ_{(u,.)} - \\frac{\\sum_{v=1}^n μ_{(v,.)}}{n}$$\n",
        "- Item $i$ rating bias: (Initial values for ALS)\n",
        "$$b_{(.,i)} = μ_{(.,i)} - \\frac{\\sum_{j=1}^m μ_{(.,j)}}{m}$$\n",
        "\n",
        "## ALS\n",
        "- Optimize global bias\n",
        "  \n",
        "- Objective function:\n",
        "$$l(B_u, B_i) = \\frac{1}{2}||Π_{Ω}(A - μ^{n⨉m} - B_u·1^{1⨉m} - (B_i·1^{1⨉n})^T)||_{F}^{2} + \\frac{λ}{2}(||B_u||_{2}^{2} + ||B_i||_{2}^{2})$$\n",
        "\n",
        "- $B_u$ is the column vector for all $b_{(u,.)}$ ($b_{(1,.)},...,b_{(n,.)}$)\n",
        "- $B_i$ is the column vector for all $b_{(.,i)}$ ($b_{(.,1)},...,b_{(.,m)}$)\n",
        "\n",
        "- Focus on the contribution to the error of a single $b_{(u,.)}$:\n",
        "- Where does $b_{(u,.)}$ appear in error?\n",
        "$$l_{B_i}(b_{(u,.)}) = \\frac{1}{2}\\sum_{i=1}^m ω_{ui}(a_{ui} - μ - b_{(u,.)} - b_{(.,i)})^2 + \\frac{λ}{2}b_{(u,.)}^2$$\n",
        "\n",
        "- Partial derivative with respect to $b_{(u,.)}$\n",
        "$$\\frac{∂l}{∂b_{(u,.)}} = \\frac{1}{2}\\sum_{i=1}^m 2ω_{ui}(a_{ui} - μ - b_{(u,.)} - b_{(.,i)})(-1) + \\frac{λ}{2}2b_{(u,.)}$$\n",
        "\n",
        "- Set $\\frac{∂l}{∂b_{(u,.)}} = 0$\n",
        "$$0 = -\\sum_{i=1}^m ω_{ui}(a_{ui} - μ - b_{(u,.)} - b_{(.,i)}) + λb_{(u,.)}$$\n",
        "$$λb_{(u,.)} = \\sum_{i=1}^m ω_{ui}(a_{ui} - μ - b_{(.,i)}) - \\sum_{i=1}^m ω_{ui}b_{(u,.)}$$\n",
        "$$λb_{(u,.)} + \\sum_{i=1}^m ω_{ui}b_{(u,.)} = \\sum_{i=1}^m ω_{ui}(a_{ui} - μ - b_{(.,i)})$$\n",
        "$$b_{(u,.)}(λ + \\sum_{i=1}^m ω_{ui}) = \\sum_{i=1}^m ω_{ui}(a_{ui} - μ - b_{(.,i)})$$\n",
        "\n",
        "- Thus,\n",
        "$$b_{(u,.)}^* = (λ + \\sum_{i=1}^m ω_{ui})^{-1}\\sum_{i=1}^m ω_{ui}(a_{ui} - μ - b_{(.,i)})$$\n",
        "- Note that $(λ + \\sum_{i=1}^m ω_{ui}) > 0$ because $ω_{ui}∈\\{0,1\\}$ and $λ > 0$\n",
        "\n",
        "- Equations for all $b_{(u,.)}$, $1<=u<=n$\n",
        "$$(λ + \\sum_{i=1}^m ω_{1i})b_{(1,.)} = \\sum_{i=1}^m ω_{1i}(a_{1i} - μ - b_{(.,i)})$$\n",
        "$$⋮$$\n",
        "$$(λ + \\sum_{i=1}^m ω_{ni})b_{(n,.)} = \\sum_{i=1}^m ω_{ni}(a_{ni} - μ - b_{(.,i)})$$\n",
        "\n",
        "- Thus,\n",
        "$$\\begin{bmatrix} (λ + \\sum_{i=1}^m ω_{1i}) \\\\ ⋮ \\\\ (λ + \\sum_{i=1}^m ω_{ni}) \\end{bmatrix}\\begin{bmatrix} b_{(1,.)}^* \\\\ ⋮ \\\\ b_{(n,.)}^* \\end{bmatrix} = \\begin{bmatrix} \\sum_{i=1}^m ω_{1i}(a_{1i} - μ - b_{(.,i)}) \\\\ ⋮ \\\\ \\sum_{i=1}^m ω_{ni}(a_{ni} - μ - b_{(.,i)}) \\end{bmatrix}$$\n",
        "- Which is equivalent to,\n",
        "$$(λ^{n⨉n} + diag(Ω·1^{m⨉1}))\\begin{bmatrix} b_{(1,.)}^* \\\\ ⋮ \\\\ b_{(n,.)}^* \\end{bmatrix} = (Π_Ω(A - μ^{n⨉m} - 1^{n⨉1}·B_i^T))·1^{m⨉1}$$\n",
        "\n",
        "- Similarly for all $b_{(.,i)}$,\n",
        "$$(λ^{m⨉m} + diag(Ω^T·1^{n⨉1}))\\begin{bmatrix} b_{.,1)}^* \\\\ ⋮ \\\\ b_{(.,m)}^* \\end{bmatrix} = (Π_{Ω^T}(A^T - μ^{m⨉n} - 1^{m⨉1}·B_u^T))·1^{n⨉1}$$\n",
        "\n",
        "- Global estimation for rating of item $i$ by user $u$:\n",
        "$$b_{ui} = μ + b_{(u,.)} + b_{(.,i)}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class GBias():\n",
        "    \n",
        "    def __init__(self, A, lambda1=0.001, epochs=5):\n",
        "        self.A = A\n",
        "        self.W = (self.A > 0).astype(int)\n",
        "        self.num_users, self.num_items = self.A.shape\n",
        "        self.lambda1 = lambda1\n",
        "        self.epochs = epochs\n",
        "        \n",
        "        # Initialize the biases\n",
        "        self.global_mean = np.sum(self.W * self.A)/np.sum(self.W)\n",
        "        Mu = np.array([np.sum(Wu * Au)/np.sum(Wu) for Au, Wu in zip(self.A, self.W)])\n",
        "        Mi = np.array([np.sum(Wi * Ai)/np.sum(Wi) for Ai, Wi in zip(self.A.T, self.W.T)])\n",
        "\n",
        "        self.Bu = Mu - np.mean(Mu)\n",
        "        self.Bi = Mi - np.mean(Mi)\n",
        "\n",
        "        self.Bu = np.reshape(self.Bu, (self.Bu.shape[0],1))\n",
        "        self.Bi = np.reshape(self.Bi, (self.Bi.shape[0],1))\n",
        "    \n",
        "    def _loss(self):\n",
        "        return ((1/2) * np.sum((self.W * (self.A - self.global_mean - np.dot(self.Bu, np.ones((1, self.num_items))) - np.dot(self.Bi, np.ones((1, self.num_users))).T) ** 2))\n",
        "                + (self.lambda1/2) * (np.sum(self.Bu ** 2) + np.sum(self.Bi ** 2)))\n",
        "    \n",
        "    def train(self, test_matrix=None):\n",
        "        error_progress = {\n",
        "            \"train_rmse\": [],\n",
        "            \"test_rmse\": [],\n",
        "        }\n",
        "        for epoch in tqdm(range(self.epochs)):\n",
        "            self._als()\n",
        "            rec_A = self.reconstruct_matrix()\n",
        "            train_rmse = get_rmse_score(rec_A, self.A)\n",
        "            error_progress[\"train_rmse\"].append(train_rmse)\n",
        "            if test_matrix is not None:\n",
        "                test_rmse = get_rmse_score(rec_A, test_matrix)\n",
        "                error_progress[\"test_rmse\"].append(test_rmse)\n",
        "            # print(error_progress)\n",
        "        return error_progress\n",
        "    \n",
        "    def _als(self):\n",
        "        self.Bi = np.linalg.solve(self.lambda1 + np.diag(np.dot(self.W.T, np.ones((self.num_users,1))).T[0]),\n",
        "                                    np.dot(\n",
        "                                        self.W.T * (self.A.T - self.global_mean - np.dot(np.ones((self.num_items, 1)), self.Bu.T)),\n",
        "                                        np.ones((self.num_users, 1))\n",
        "                                    )\n",
        "                                )\n",
        "        # print(\"Loss l(Bu,Bi) after solving for Bi:\", self._loss())\n",
        "\n",
        "        self.Bu = np.linalg.solve(self.lambda1 + np.diag(np.dot(self.W, np.ones((self.num_items,1))).T[0]),\n",
        "                                np.dot(\n",
        "                                    self.W * (self.A - self.global_mean - np.dot(np.ones((self.num_users, 1)), self.Bi.T)),\n",
        "                                    np.ones((self.num_items, 1))\n",
        "                                )\n",
        "                            )\n",
        "        # print(\"Loss l(Bu,Bi) after solving for Bu:\", self._loss())\n",
        "    \n",
        "    def reconstruct_matrix(self):\n",
        "        \"\"\"\n",
        "        Compute the full matrix using biases\n",
        "        \"\"\"\n",
        "        biases = self.global_mean + np.array([self.Bu.T[0]]*self.num_items).T + np.array([self.Bi.T[0]]*self.num_users)\n",
        "        return biases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# A, test_matrix = import_data_to_matrix_split()\n",
        "# model = GBias(A, lambda1=0.001, epochs=5)\n",
        "# model.train(test_matrix=test_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "A = import_data_to_matrix()\n",
        "model = GBias(A, lambda1=0.001, epochs=5)\n",
        "model.train()\n",
        "rec_A = model.reconstruct_matrix()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rec_A[rec_A>5] = 5\n",
        "rec_A[rec_A<1] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pu0u1JOt-Zqq"
      },
      "outputs": [],
      "source": [
        "extract_submission(rec_A, file=\"global\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "CIL_project.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "0a87d56eeac580fc40402592e75d25bb128c24f68de3c5b4d3abca5cf6a5446a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
