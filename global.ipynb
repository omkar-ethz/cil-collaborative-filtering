{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Global Bias Method\n",
        "- Idea: Each user and each item has a specific bias towards ratings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdZ-qzPO_Mbw"
      },
      "source": [
        "## Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sr5kvYqx-4kA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "from utils import import_data_to_matrix, extract_submission\n",
        "from utils import NUMBER_OF_MOVIES, NUMBER_OF_USERS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiZ4bBQu_UEY"
      },
      "source": [
        "## Basic Settings\n",
        "- $λ = 0.01$, 20 ALS (global bias) iterations "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2cusQMrf-VN2"
      },
      "outputs": [],
      "source": [
        "lambda_ = 0.01\n",
        "iterations = 20"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flpq9Ir2_WX_"
      },
      "source": [
        "## Data Preprocessings\n",
        "- Extract data to row-column format\n",
        "- Impute missing data with 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Rating matrix A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wNc3UeBc6gn7"
      },
      "outputs": [],
      "source": [
        "A = import_data_to_matrix()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Observation matrix Ω"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "W = (A > 0).astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Global Bias\n",
        "- Each user and each item has a specific bias towards ratings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Global rating mean:\n",
        "$$μ = \\frac{\\sum_{u=1}^n \\sum_{i=1}^m ω_{ui}a_{ui}}{\\sum_{u=1}^n \\sum_{i=1}^m ω_{ui}}$$\n",
        "- User $u$ rating mean:\n",
        "$$μ_{(u,.)} = \\frac{\\sum_{i=1}^m ω_{ui}a_{ui}}{\\sum_{i=1}^m ω_{ui}}$$\n",
        "- Item $i$ rating mean:\n",
        "$$μ_{(.,i)} = \\frac{\\sum_{u=1}^n ω_{ui}a_{ui}}{\\sum_{u=1}^n ω_{ui}}$$\n",
        "- User $u$ rating bias: (Initial values for ALS)\n",
        "$$b_{(u,.)} = μ_{(u,.)} - \\frac{\\sum_{v=1}^n μ_{(v,.)}}{n}$$\n",
        "- Item $i$ rating bias: (Initial values for ALS)\n",
        "$$b_{(.,i)} = μ_{(.,i)} - \\frac{\\sum_{j=1}^m μ_{(.,j)}}{m}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "global_mean = np.sum(W * A)/np.sum(W)\n",
        "Mu = np.array([np.sum(Wu * Au)/np.sum(Wu) for Au, Wu in zip(A, W)])\n",
        "Mi = np.array([np.sum(Wi * Ai)/np.sum(Wi) for Ai, Wi in zip(A.T, W.T)])\n",
        "\n",
        "Bu = Mu - np.mean(Mu)\n",
        "Bi = Mi - np.mean(Mi)\n",
        "\n",
        "Bu = np.reshape(Bu, (Bu.shape[0],1))\n",
        "Bi = np.reshape(Bi, (Bi.shape[0],1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ALS\n",
        "- Optimize global bias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Objective function:\n",
        "$$l(B_u, B_i) = \\frac{1}{2}||Π_{Ω}(A - μ^{n⨉m} - B_u·1^{1⨉m} - (B_i·1^{1⨉n})^T)||_{F}^{2} + \\frac{λ}{2}(||B_u||_{2}^{2} + ||B_i||_{2}^{2})$$\n",
        "\n",
        "- $B_u$ is the column vector for all $b_{(u,.)}$ ($b_{(1,.)},...,b_{(n,.)}$)\n",
        "- $B_i$ is the column vector for all $b_{(.,i)}$ ($b_{(.,1)},...,b_{(.,m)}$)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def loss(A, Bu, Bi, W, l, global_mean):\n",
        "    return ((1/2) * np.sum((W * (A - global_mean - np.dot(Bu, np.ones((1, NUMBER_OF_MOVIES))) - np.dot(Bi, np.ones((1, NUMBER_OF_USERS))).T) ** 2))\n",
        "            + (l/2) * (np.sum(Bu ** 2) + np.sum(Bi ** 2)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Focus on the contribution to the error of a single $b_{(u,.)}$:\n",
        "- Where does $b_{(u,.)}$ appear in error?\n",
        "$$l_{B_i}(b_{(u,.)}) = \\frac{1}{2}\\sum_{i=1}^m ω_{ui}(a_{ui} - μ - b_{(u,.)} - b_{(.,i)})^2 + \\frac{λ}{2}b_{(u,.)}^2$$\n",
        "\n",
        "- Partial derivative with respect to $b_{(u,.)}$\n",
        "$$\\frac{∂l}{∂b_{(u,.)}} = \\frac{1}{2}\\sum_{i=1}^m 2ω_{ui}(a_{ui} - μ - b_{(u,.)} - b_{(.,i)})(-1) + \\frac{λ}{2}2b_{(u,.)}$$\n",
        "\n",
        "- Set $\\frac{∂l}{∂b_{(u,.)}} = 0$\n",
        "$$0 = -\\sum_{i=1}^m ω_{ui}(a_{ui} - μ - b_{(u,.)} - b_{(.,i)}) + λb_{(u,.)}$$\n",
        "$$λb_{(u,.)} = \\sum_{i=1}^m ω_{ui}(a_{ui} - μ - b_{(.,i)}) - \\sum_{i=1}^m ω_{ui}b_{(u,.)}$$\n",
        "$$λb_{(u,.)} + \\sum_{i=1}^m ω_{ui}b_{(u,.)} = \\sum_{i=1}^m ω_{ui}(a_{ui} - μ - b_{(.,i)})$$\n",
        "$$b_{(u,.)}(λ + \\sum_{i=1}^m ω_{ui}) = \\sum_{i=1}^m ω_{ui}(a_{ui} - μ - b_{(.,i)})$$\n",
        "\n",
        "- Thus,\n",
        "$$b_{(u,.)}^* = (λ + \\sum_{i=1}^m ω_{ui})^{-1}\\sum_{i=1}^m ω_{ui}(a_{ui} - μ - b_{(.,i)})$$\n",
        "- Note that $(λ + \\sum_{i=1}^m ω_{ui}) > 0$ because $ω_{ui}∈\\{0,1\\}$ and $λ > 0$\n",
        "\n",
        "- Equations for all $b_{(u,.)}$, $1<=u<=n$\n",
        "$$(λ + \\sum_{i=1}^m ω_{1i})b_{(1,.)} = \\sum_{i=1}^m ω_{1i}(a_{1i} - μ - b_{(.,i)})$$\n",
        "$$⋮$$\n",
        "$$(λ + \\sum_{i=1}^m ω_{ni})b_{(n,.)} = \\sum_{i=1}^m ω_{ni}(a_{ni} - μ - b_{(.,i)})$$\n",
        "\n",
        "- Thus,\n",
        "$$\\begin{bmatrix} (λ + \\sum_{i=1}^m ω_{1i}) \\\\ ⋮ \\\\ (λ + \\sum_{i=1}^m ω_{ni}) \\end{bmatrix}\\begin{bmatrix} b_{(1,.)}^* \\\\ ⋮ \\\\ b_{(n,.)}^* \\end{bmatrix} = \\begin{bmatrix} \\sum_{i=1}^m ω_{1i}(a_{1i} - μ - b_{(.,i)}) \\\\ ⋮ \\\\ \\sum_{i=1}^m ω_{ni}(a_{ni} - μ - b_{(.,i)}) \\end{bmatrix}$$\n",
        "- Which is equivalent to,\n",
        "$$(λ^{n⨉n} + diag(Ω·1^{m⨉1}))\\begin{bmatrix} b_{(1,.)}^* \\\\ ⋮ \\\\ b_{(n,.)}^* \\end{bmatrix} = (Π_Ω(A - μ^{n⨉m} - 1^{n⨉1}·B_i^T))·1^{m⨉1}$$\n",
        "\n",
        "- Similarly for all $b_{(.,i)}$,\n",
        "$$(λ^{m⨉m} + diag(Ω^T·1^{n⨉1}))\\begin{bmatrix} b_{.,1)}^* \\\\ ⋮ \\\\ b_{(.,m)}^* \\end{bmatrix} = (Π_{Ω^T}(A^T - μ^{m⨉n} - 1^{m⨉1}·B_u^T))·1^{n⨉1}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2ospRbX_scj",
        "outputId": "28886985-c2d7-45f6-e7de-623e57006120"
      },
      "outputs": [],
      "source": [
        "for epoch in tqdm(range(iterations)):\n",
        "    Bi = np.linalg.solve(lambda_ + np.diag(np.dot(W.T, np.ones((NUMBER_OF_USERS,1))).T[0]),\n",
        "                            np.dot(\n",
        "                                W.T * (A.T - global_mean - np.dot(np.ones((NUMBER_OF_MOVIES, 1)), Bu.T)),\n",
        "                                np.ones((NUMBER_OF_USERS, 1))\n",
        "                            )\n",
        "                        )\n",
        "\n",
        "    print(\"Loss l(Bu,Bi) after solving for Bi:\", loss(A, Bu, Bi, W, lambda_, global_mean))\n",
        "\n",
        "    Bu = np.linalg.solve(lambda_ + np.diag(np.dot(W, np.ones((NUMBER_OF_MOVIES,1))).T[0]),\n",
        "                            np.dot(\n",
        "                                W * (A - global_mean - np.dot(np.ones((NUMBER_OF_USERS, 1)), Bi.T)),\n",
        "                                np.ones((NUMBER_OF_MOVIES, 1))\n",
        "                            )\n",
        "                        )\n",
        "\n",
        "    print(\"Loss l(Bu,Bi) after solving for Bu:\", loss(A, Bu, Bi, W, lambda_, global_mean))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Global estimation for rating of item $i$ by user $u$:\n",
        "$$b_{ui} = μ + b_{(u,.)} + b_{(.,i)}$$\n",
        "- Reconstruct data from the result of ALS (global bias) after 20 iterations (only not observed)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "biases = global_mean + np.array([Bu.T[0]]*NUMBER_OF_MOVIES).T + np.array([Bi.T[0]]*NUMBER_OF_USERS)\n",
        "\n",
        "rec_A = A + (biases * (W^1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPJUBrFP_dRn"
      },
      "source": [
        "## Export Predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pu0u1JOt-Zqq"
      },
      "outputs": [],
      "source": [
        "extract_submission(rec_A, file=\"global\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "CIL_project.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
