{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils import import_data_to_matrix_split, extract_submission, import_data_to_matrix\n",
    "from utils import get_rmse_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IRSVD():\n",
    "\n",
    "    def __init__(self, A, biases=\"mean\", features=324, eta=0.01, lambda1=0.02, lambda2=0.05, epochs=15):\n",
    "        \"\"\"\n",
    "        Perform matrix decomposition to predict empty\n",
    "        entries in a matrix.\n",
    "        \"\"\"\n",
    "        self.A = A\n",
    "        train_users, train_items = self.A.nonzero()\n",
    "        self.train_entries = [(user, item, self.A[user][item]) \n",
    "                              for user, item in zip(train_users, train_items)]\n",
    "        self.W = (self.A > 0).astype(int)\n",
    "        self.num_users, self.num_items = self.A.shape\n",
    "        self.features = features\n",
    "        self.eta = eta\n",
    "        self.lambda1 = lambda1\n",
    "        self.lambda2 = lambda2\n",
    "        self.epochs = epochs\n",
    "        \n",
    "        # Initialize user and item latent feature matrice\n",
    "        self.U = np.random.normal(scale=1./self.features, size=(self.num_users, self.features))\n",
    "        self.V = np.random.normal(scale=1./self.features, size=(self.num_items, self.features))\n",
    "        \n",
    "        # Initialize the biases\n",
    "        self.global_mean = np.sum(self.W * self.A)/np.sum(self.W)\n",
    "        if biases == \"zero\":\n",
    "            self.Bu = np.zeros(self.num_users)\n",
    "            self.Bi = np.zeros(self.num_items)\n",
    "        else:\n",
    "            Mu = np.array([np.sum(Wu * Au)/np.sum(Wu) for Au, Wu in zip(self.A, self.W)])\n",
    "            Mi = np.array([np.sum(Wi * Ai)/np.sum(Wi) for Ai, Wi in zip(self.A.T, self.W.T)])\n",
    "\n",
    "            self.Bu = Mu - np.mean(Mu)\n",
    "            self.Bi = Mi - np.mean(Mi)\n",
    "\n",
    "        self.Bu = np.reshape(self.Bu, (self.Bu.shape[0],1))\n",
    "        self.Bi = np.reshape(self.Bi, (self.Bi.shape[0],1))\n",
    "\n",
    "    def train(self, test_matrix=None):\n",
    "        # Perform stochastic gradient descent for number of epochs\n",
    "        error_progress = {\n",
    "            \"train_rmse\": [],\n",
    "            \"test_rmse\": [],\n",
    "        }\n",
    "        for epoch in tqdm(range(self.epochs)):\n",
    "            # shuffling will help during training\n",
    "            np.random.shuffle(self.train_entries)\n",
    "            # print(\"Entering sgd\")\n",
    "            self._sgd()\n",
    "            # print(\"Finishing sgd\")\n",
    "            rec_A = self.reconstruct_matrix()\n",
    "            train_rmse = get_rmse_score(rec_A, self.A)\n",
    "            error_progress[\"train_rmse\"].append(train_rmse)\n",
    "            if test_matrix is not None:\n",
    "                test_rmse = get_rmse_score(rec_A, test_matrix)\n",
    "                error_progress[\"test_rmse\"].append(test_rmse)\n",
    "            # print(error_progress)\n",
    "        return error_progress\n",
    "\n",
    "    def _sgd(self):\n",
    "        \"\"\"\n",
    "        Perform stochastic gradient descent\n",
    "        \"\"\"\n",
    "        for user, item, rating in self.train_entries:\n",
    "            # Compute prediction and error\n",
    "            prediction = self.global_mean + self.Bu[user] + self.Bi[item] + np.dot(self.U[user, :], self.V[item, :].T)\n",
    "            error = (rating - prediction)\n",
    "\n",
    "            # Update biases\n",
    "            self.Bu[user] += self.eta * (error - self.lambda2 * self.Bu[user])\n",
    "            self.Bi[item] += self.eta * (error - self.lambda2 * self.Bi[item])\n",
    "\n",
    "            # Update user and item feature matrices\n",
    "            temp_U = np.copy(self.U[user, :])\n",
    "            self.U[user, :] += self.eta * (error * self.V[item, :] - self.lambda1 * self.U[user,:])\n",
    "            self.V[item, :] += self.eta * (error * temp_U - self.lambda1 * self.V[item,:])\n",
    "\n",
    "    def reconstruct_matrix(self):\n",
    "        \"\"\"\n",
    "        Compute the reconstructed matrix using biases, U and V\n",
    "        \"\"\"\n",
    "        biases = self.global_mean + np.array([self.Bu.T[0]]*self.num_items).T + np.array([self.Bi.T[0]]*self.num_users)\n",
    "        return biases + np.dot(self.U, self.V.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Best parameters so far\n",
    "$$irsvd (k=324, eta=0.01, lambda1=0.02, lambda2=0.05, epochs=15)$$\n",
    "$$irsvd (k=296, eta=0.01, lambda1=0.02, lambda2=0.05, epochs=14)$$\n",
    "$$irsvd (k=148, eta=0.01, lambda1=0.02, lambda2=0.05, epochs=13)$$\n",
    "$$irsvd (k=96, eta=0.01, lambda1=0.02, lambda2=0.05, epochs=13)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A, test_matrix = import_data_to_matrix_split()\n",
    "# model = IRSVD(A, biases=\"zero\", features=324, eta=0.01, lambda1=0.02, lambda2=0.05, epochs=13)\n",
    "# model.train(test_matrix=test_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = import_data_to_matrix()\n",
    "model = IRSVD(A, biases=\"mean\", features=324, eta=0.01, lambda1=0.02, lambda2=0.05, epochs=15)\n",
    "model.train()\n",
    "rec_A = model.reconstruct_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_A[rec_A>5] = 5\n",
    "rec_A[rec_A<1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_submission(rec_A, file=\"irsvd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pd = pd.read_csv(\"./data/data_train.csv\")\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "print(len(data_pd))\n",
    "for train_i, test_i in kf.split(data_pd):\n",
    "    print(train_i)\n",
    "    print(test_i)\n",
    "    split = data_pd.iloc[train_i]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0a87d56eeac580fc40402592e75d25bb128c24f68de3c5b4d3abca5cf6a5446a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
